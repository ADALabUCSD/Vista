{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../code/python')\n",
    "\n",
    "import findspark\n",
    "import pyspark\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘metastore_db’: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! rm -r metastore_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/users/snakanda/vista/spark-2.2.0-bin-hadoop2.7')\n",
    "\n",
    "sc = pyspark.SparkContext(appName=\"vista\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 88 from C header, got 96 from PyObject\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:45: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 88 from C header, got 96 from PyObject\n",
      "  from . import h5a, h5d, h5ds, h5f, h5fd, h5g, h5r, h5s, h5t, h5p, h5z\n",
      "/usr/local/lib/python2.7/dist-packages/h5py/_hl/group.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 88 from C header, got 96 from PyObject\n",
      "  from .. import h5, h5g, h5i, h5o, h5r, h5t, h5l, h5p, h5s, h5d\n"
     ]
    }
   ],
   "source": [
    "from vista import Vista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://128.105.145.38:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>vista</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=vista>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vista Configs(join, cpu, np, heap, f_core, pers): b, 7, 238, 133, 0.972117558402, deser\n",
      "{-1: 0.821356783919598, -3: 0.8329145728643216, -2: 0.8261306532663316}\n",
      "Runtime (min): 22.1466980338\n"
     ]
    }
   ],
   "source": [
    "def downstream_ml_func(features_df, results_dict, layer_index):\n",
    "    lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=50, regParam=0.5)\n",
    "    train_df, test_df = features_df.randomSplit([0.8, 0.2], seed=2019)\n",
    "    model = lr.fit(train_df)\n",
    "    predictions = model.transform(test_df)\n",
    "    evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                                  metricName=\"accuracy\")\n",
    "    results_dict[layer_index] = evaluator.evaluate(predictions)\n",
    "    return results_dict\n",
    "\n",
    "prev_time = time.time()\n",
    "# mem_sys_rsv is an optional parameter. If not set a default value of 3 will be used.\n",
    "vista = Vista(\"vista-example\", 150, 8, 1, 'alexnet', 3, 0, downstream_ml_func,\n",
    "                  '/users/snakanda/vista/data/foods/foods.csv',\n",
    "                  '/users/snakanda/vista/data/foods/images',\n",
    "                  20129, 130, mem_sys_rsv=3)\n",
    "\n",
    "print(vista.run())\n",
    "print(\"Runtime (min): \" + str((time.time()-prev_time)/60.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Features Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import array, col\n",
    "from pyspark.sql.types import StringType, FloatType, IntegerType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "toDense = F.udf(lambda v: Vectors.dense(v.toArray()), VectorUDT())\n",
    "\n",
    "def get_struct_df(sc, data_file_path):\n",
    "    sql_context = pyspark.SQLContext(sc)\n",
    "    struct_df = sql_context.read.format('csv').options(header='false').load(data_file_path)\n",
    "    col_names = struct_df.schema.names\n",
    "    for col_name in col_names[1:-1]:\n",
    "        struct_df = struct_df.withColumn(col_name, struct_df[col_name].cast(FloatType()))\n",
    "        \n",
    "    struct_df = VectorAssembler(inputCols=col_names[1:-1], outputCol=\"features\").transform(struct_df)\n",
    "    struct_df = struct_df.withColumn(\"features\", toDense(\"features\"))\n",
    "    struct_df = struct_df.withColumn(\"id\", struct_df[col_names[0]].cast(StringType())) \\\n",
    "        .withColumn(\"label\", struct_df[col_names[-1]].cast(IntegerType())) \\\n",
    "        .select(\"id\", \"features\", \"label\")\n",
    "    return struct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = get_struct_df(sc, '/users/snakanda/vista/data/foods/foods.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.8067371526924023}\n"
     ]
    }
   ],
   "source": [
    "print(downstream_ml_func(features_df, {}, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
